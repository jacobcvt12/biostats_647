---
title: "Homework 9"
author: "Jacob Carey"
date: \today
header-includes:
    - \usepackage{amsthm}
    - \usepackage{mathtools}
output: pdf_document
---

1.
    (i)
        Likelihood:
        MLE:
        Score function:
        Observed Fisher Information:
        Expected Fisher Information:

    (ii)
        Likelihood: $$\prod_{i=1}^n \frac{\theta^{x_i}e^{-\theta}}{x_i!}$$
        MLE: $$\frac{1}{n}\sum_{i=1}^n x_i$$
        Score function: $$-n + \frac{1}{\theta}\sum_{i=1}^n x_i$$
        Observed Fisher Information: $$\frac{1}{\theta^2}\sum_{i=1}^n x_i$$
        Expected Fisher Information: $$\frac{1}{\theta^2}E \Big[\sum x_i \Big]=\frac{n}{\theta}$$

    (iii)
        Likelihood:
        MLE:
        Score function:
        Observed Fisher Information:
        Expected Fisher Information:

2.
    (i)
    $$
    \prod (2\pi \sigma^2)^{-1/2} \exp \Big\{-1/2 \sigma^2 (y_i - \beta x_i)^2 \Big\} = (2\pi \sigma^2)^{-n/2} \exp \Big\{ -\frac{1}{2 \sigma^2} \sum (y_i-\beta x_i)^2 \Big\}
    $$

    (ii)

    (iii)

    (iv)

    (v)

    (vi)

    (vii)

3.
    $$
    \begin{aligned}
    P(X \geq k) &\leq \frac{E[X]}{k} \\
    P_{\theta_0} \Big(\frac{f(x;\theta_1)}{f(x;\theta_0)}\geq k \Big) &\leq \frac{E_{\theta_0} \Big(\frac{f(x;\theta_1)}{f(x;\theta_0)}\Big)}{k} \\
    E_{\theta_0} \Big(\frac{f(x;\theta_1)}{f(x;\theta_0)}\Big) = \int_X f(x;\theta_0)\frac{f(x;\theta_1)}{f(x;\theta_0)}dx &=\int_X f(x;\theta_1) dx = 1 \\
    \implies P_{\theta_0} \Big(\frac{f(x;\theta_1)}{f(x;\theta_0)}\geq k \Big) &\leq \frac{1}{k} \qedsymbol
    \end{aligned}
    $$

4. 
    $$
    \begin{aligned}
        \text{MSE}(\hat{\theta})&=E[(\hat{\theta}-\theta^2)] \\
        &=E[\hat{\theta}-E[\hat{\theta}]+E[\hat{\theta}]-\theta)^2] \\
        &=E[(\hat{\theta}-E[\hat{\theta}])^2]+2(E[\hat{\theta}]-\theta)E[\hat{\theta}-E(\hat{\theta})]+E[E(\hat{\theta}-\theta)^2] \\
        &= E[(\hat{\theta}-E[\hat{\theta}] + (E[\hat{\theta}]-\theta)^2 \\
        &= \text{Var}(\hat{\theta}) + \text{Bias}(\hat{\theta}, \theta)^2 \qedsymbol
    \end{aligned}
    $$

5. (a)
    Joint density:
    $$
    \prod f(x_i; \theta) = \prod \frac{e^{-x_i/\theta}}{\theta} = \theta^{-1}\exp\{-\frac{1}{\theta}\sum x_i\}
    $$

    Score function:
    $$
    \begin{aligned}
    \log \prod f(x_i;\theta) &= \sum \log\{\theta^{-1}\exp(-x_i/\theta)\} \\
    &= -n \log \theta - \theta^{-1} \sum x_i \\
    \implies \frac{\partial \log f(x;\theta)}{\partial \theta} &= -\frac{n}{\theta} + \frac{n\bar{x}}{\theta^2}
    \end{aligned}
    $$
    (b)
    $$
    \begin{aligned}
    -\frac{n}{\theta}+\frac{n\bar{x}}{\theta^2} &= 0 \\
    \boxed{\hat{\theta}=\bar{x}}
    \end{aligned}
    $$
    Unbiased:
    $$
    E[\hat{\theta}] = E[\frac{1}{n}\sum x_i] = \frac{1}{n}\sum \theta = \theta
    $$
    Consistent:
    $$
    P(|1/n\sum x_i - \theta|\geq \epsilon) = P((1/n \sum x_i - \theta) \geq \epsilon^2) = E(1/n \sum x_i - \theta)^2/ \epsilon^2
    $$
    $$
    E(1/n\sum x_i-\theta)^2 = 0 \implies P(\hat{\theta} - \theta \geq \epsilon) = 0
    $$
    Variance:
    $$
    \text{Var}(\bar{X})=\frac{1}{n^2}\text{Var}(\sum X_i) = \frac{1}{n^2}(E([\sum x_i]^2)-[E(\sum x_i)]^2)=\frac{1}{n^2} \sum \text{Var}(X_i)
    $$

6.

7.
